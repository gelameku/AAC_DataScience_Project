{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project1 - Housing In Mexico\n",
    "\n",
    "Here, we'll learn:\n",
    "\n",
    "- How to organize information using basic Python data structures.\n",
    "- How to import data from CSV files and clean it using the pandas library.\n",
    "- How to create data visualizations like scatter and box plots.\n",
    "- How to examine the relationship between two variables using correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem / Question:**\n",
    "- Which factor, location or size, exerts a greater influence on house prices in Mexico?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Collection:**\n",
    "\n",
    "In this project, we'll work with mexico-real-esate datasets \n",
    "- Data Source: open data\n",
    "- Data type: csv (#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wrangling / Preprocessing:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling (Munging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first part of any data science project is preparing your data, which means making sure its in the right place and format for you to conduct your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1   Import**\n",
    "-  The first step of any data preparation is importing your raw data and cleaning it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/user/DSFolder/mx/mexico-real-estate-1.csv\")\n",
    "df2 = pd.read_csv(\"C:/Users/user/DSFolder/mx/mexico-real-estate-2.csv\")\n",
    "df3 = pd.read_csv(\"C:/Users/user/DSFolder/mx/mexico-real-estate-3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect each DataFrames: \n",
    "- By looking at its `shape` attribute. \n",
    "- Then use the `info` method to see the data types and number of missing values for each column. \n",
    "- Finally, use the `head` method to determine to look at the first five rows of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean df1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can observe that:\n",
    "- There are many missed rows (NAN) in `lan` and `lon` columns\n",
    "- The column `Unamed:0` should be dropped\n",
    "- The data type for the `\"price_usd\"` column is `object` when it should be `float`. (this is because of `'$'` and `','`)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Removing NaN value in the exsiting data frame, not new\n",
    "df1.dropna(inplace=True)\n",
    "# Drop the first column\n",
    "df1.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "\n",
    "# Transorm price from object to float\n",
    "df1[\"price_usd\"]=(\n",
    "    df1[\"price_usd\"]\n",
    "    .str.replace(\"$\",\"\",regex=False)\n",
    "    .str.replace(\",\",\"\")\n",
    "    .astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB:\n",
    "- `replace(source, replacement, count)`- is a method associated with strings that allows you to replace occurrences of a substring (source) with another substring (replacement). Optionally, you can specify the maximum number of replacements to make with the count parameter (default is all occurrences).\n",
    "- regex=False: This is an optional argument for the replace() method. It specifies whether to treat the source string as a literal string (False) or a regular expression (True). Here, regex=False indicates we're dealing with a plain string, not a pattern.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_string = \"This string has $10 and $20.\"\n",
    "modified_string = original_string.replace(\"$\", \"\")\n",
    "print(modified_string)  # Output: This string has 10 and 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean df2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can notice:\n",
    "- There are many null values (NAN) in `lan` and `lon` columns\n",
    "- The column `Unamed:0` should be dropped\n",
    "- The data type for the `\"price_mxn\"` column is `int64`. (but should be in US dollar `\"price_usd\"`)\n",
    "    - If we want to compare all the home prices in this dataset, they all need to be in the same currency.\n",
    "- Drop `\"price_mxn\"` column"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df2.dropna(inplace=True)\n",
    "df2.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "\n",
    "# Create price_usd column dividing by 16.74\n",
    "df2[\"price_usd\"]=(df2[\"price_mxn\"]/16.74). round(2)\n",
    "df2.drop(columns=[\"price_mxn\"],inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cean df3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can notice:\n",
    "- There are many null values (NAN) in `lan` and `lon` columns\n",
    "- The column `Unamed:0` should be dropped\n",
    "- Split `lat-lon` column into two separted column `lat` and `lon`\n",
    "\n",
    "- Create a `State` column from `\"place_with_parent_names\"`\n",
    "- Finally, drop the `\"place_with_parent_names\"` and `\"lat-lon\"` columns from the DataFrame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df3.dropna(inplace=True)\n",
    "df3.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "\n",
    "# split lat-lon cln into two separted cln lat and lon\n",
    "df3[[\"lat\",\"lon\"]]=df3[\"lat-lon\"].str.split(\",\", expand=True)\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df3[\"state\"]= df3[\"place_with_parent_names\"].str.split(\"|\", expand=True)[2]\n",
    "df3.drop(columns=[\"place_with_parent_names\",\"lat-lon\"],inplace=True)\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate DataFrame**\n",
    "\n",
    "- You have three clean DataFrames, and \n",
    "- now it's time to combine them into a single DataFrame so that you can conduct your analysis. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.concat([df1,df2,df3])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save/write df**\n",
    "\n",
    "- The data is clean and in a single DataFrame, and now you need to save it as a CSV file so that you can examine it in your exploratory data analysis."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.to_csv(\"C:/Users/user/DSFolder/mx/mexicoData_clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
